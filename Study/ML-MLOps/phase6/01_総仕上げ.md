# Phase 6-1: 総仕上げ ～ 機械学習プロジェクト ～

## 学習目標

この単元を終えると、以下ができるようになります：

- End-to-End の機械学習プロジェクトを実行できる
- 本番運用を考慮した設計ができる
- 継続的な改善サイクルを回せる

## 総合演習: 顧客離脱予測システム

### 要件

```
ビジネス要件:
- サブスクリプションサービスの顧客離脱を予測
- 月次で離脱リスクをスコアリング
- 高リスク顧客にキャンペーンを送信

技術要件:
- 精度 80% 以上
- Recall 重視（離脱を見逃さない）
- 日次バッチ処理
- API でリアルタイム予測も可能
```

### 完全な実装

```python
# churn_prediction_project/train.py
"""
顧客離脱予測モデルの訓練スクリプト
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import classification_report, roc_auc_score
from sklearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
import mlflow
import mlflow.sklearn
import joblib

def load_data():
    """データ読み込み（実際は DB やファイルから）"""
    np.random.seed(42)
    n_samples = 5000
    
    data = pd.DataFrame({
        'customer_id': range(n_samples),
        'tenure_months': np.random.randint(1, 72, n_samples),
        'monthly_charges': np.random.uniform(20, 100, n_samples),
        'total_charges': np.random.uniform(100, 7000, n_samples),
        'num_support_tickets': np.random.poisson(2, n_samples),
        'num_logins_30d': np.random.poisson(15, n_samples),
        'contract_type': np.random.choice(['month-to-month', 'one_year', 'two_year'], n_samples),
        'payment_method': np.random.choice(['credit_card', 'bank_transfer', 'electronic'], n_samples)
    })
    
    # ターゲット（離脱率 20%）
    churn_prob = 0.3 - 0.005 * data['tenure_months'] + 0.002 * data['num_support_tickets']
    churn_prob = np.clip(churn_prob, 0.05, 0.5)
    data['churned'] = (np.random.random(n_samples) < churn_prob).astype(int)
    
    return data

def preprocess(df: pd.DataFrame):
    """特徴量エンジニアリング"""
    df = df.copy()
    
    # 特徴量作成
    df['avg_monthly_charges'] = df['total_charges'] / (df['tenure_months'] + 1)
    df['support_per_month'] = df['num_support_tickets'] / (df['tenure_months'] + 1)
    df['login_frequency'] = df['num_logins_30d'] / 30
    
    # カテゴリカル変数のエンコーディング
    df = pd.get_dummies(df, columns=['contract_type', 'payment_method'])
    
    return df

def train_model(df: pd.DataFrame):
    """モデル訓練"""
    # 特徴量とターゲット
    feature_cols = [c for c in df.columns if c not in ['customer_id', 'churned']]
    X = df[feature_cols]
    y = df['churned']
    
    # 分割
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # SMOTE でオーバーサンプリング
    smote = SMOTE(random_state=42)
    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)
    
    # パイプライン
    pipeline = Pipeline([
        ('scaler', StandardScaler()),
        ('classifier', GradientBoostingClassifier(
            n_estimators=100,
            max_depth=5,
            learning_rate=0.1,
            random_state=42
        ))
    ])
    
    # MLflow でログ
    mlflow.set_experiment('churn_prediction')
    
    with mlflow.start_run(run_name='gradient_boosting'):
        # 訓練
        pipeline.fit(X_train_resampled, y_train_resampled)
        
        # 予測
        y_pred = pipeline.predict(X_test)
        y_proba = pipeline.predict_proba(X_test)[:, 1]
        
        # メトリクス
        print(classification_report(y_test, y_pred))
        auc = roc_auc_score(y_test, y_proba)
        print(f'AUC-ROC: {auc:.4f}')
        
        # ログ
        mlflow.log_params({
            'n_estimators': 100,
            'max_depth': 5,
            'learning_rate': 0.1
        })
        mlflow.log_metric('auc_roc', auc)
        
        # モデル保存
        mlflow.sklearn.log_model(pipeline, 'model')
        joblib.dump(pipeline, 'churn_model.joblib')
        joblib.dump(feature_cols, 'feature_cols.joblib')
    
    return pipeline, feature_cols

if __name__ == '__main__':
    print('Loading data...')
    df = load_data()
    
    print('Preprocessing...')
    df = preprocess(df)
    
    print('Training model...')
    model, features = train_model(df)
    
    print('Done!')
```

```python
# churn_prediction_project/api.py
"""
推論 API
"""

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import pandas as pd
import joblib

app = FastAPI(title='Churn Prediction API')

# モデル読み込み
model = joblib.load('churn_model.joblib')
feature_cols = joblib.load('feature_cols.joblib')

class CustomerData(BaseModel):
    customer_id: int
    tenure_months: int
    monthly_charges: float
    total_charges: float
    num_support_tickets: int
    num_logins_30d: int
    contract_type: str
    payment_method: str

class PredictionResult(BaseModel):
    customer_id: int
    churn_probability: float
    risk_level: str

def preprocess_input(data: CustomerData) -> pd.DataFrame:
    """入力データの前処理"""
    df = pd.DataFrame([data.dict()])
    
    # 特徴量作成
    df['avg_monthly_charges'] = df['total_charges'] / (df['tenure_months'] + 1)
    df['support_per_month'] = df['num_support_tickets'] / (df['tenure_months'] + 1)
    df['login_frequency'] = df['num_logins_30d'] / 30
    
    # One-hot
    df = pd.get_dummies(df, columns=['contract_type', 'payment_method'])
    
    # 不足列を追加
    for col in feature_cols:
        if col not in df.columns:
            df[col] = 0
    
    return df[feature_cols]

@app.get('/health')
def health():
    return {'status': 'healthy'}

@app.post('/predict', response_model=PredictionResult)
def predict(customer: CustomerData):
    try:
        # 前処理
        X = preprocess_input(customer)
        
        # 予測
        proba = model.predict_proba(X)[0, 1]
        
        # リスクレベル判定
        if proba >= 0.7:
            risk = 'high'
        elif proba >= 0.4:
            risk = 'medium'
        else:
            risk = 'low'
        
        return PredictionResult(
            customer_id=customer.customer_id,
            churn_probability=float(proba),
            risk_level=risk
        )
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post('/predict/batch')
def predict_batch(customers: list[CustomerData]):
    results = []
    for customer in customers:
        result = predict(customer)
        results.append(result)
    return results
```

## MLOps チェックリスト

### 開発

- [ ] バージョン管理（Git）
- [ ] 実験管理（MLflow）
- [ ] テスト（ユニット、統合）
- [ ] コードレビュー

### デプロイ

- [ ] CI/CD パイプライン
- [ ] コンテナ化（Docker）
- [ ] インフラ（Kubernetes, ECS）
- [ ] A/B テスト

### 運用

- [ ] モニタリング（精度、レイテンシ）
- [ ] アラート（ドリフト検出）
- [ ] ログ
- [ ] 再訓練パイプライン

## カリキュラム完了！

おめでとうございます！機械学習基礎・MLOps のカリキュラムを完了しました。

### 学んだこと

1. **機械学習基礎** - 教師あり/なし学習、評価指標
2. **データ前処理** - 欠損値、エンコーディング、スケーリング
3. **回帰・分類** - 線形回帰、ロジスティック回帰、決定木
4. **モデル評価** - 交差検証、ハイパーパラメータチューニング
5. **アンサンブル** - Random Forest, XGBoost, LightGBM
6. **ディープラーニング** - PyTorch, CNN
7. **MLOps** - MLflow, デプロイ, 監視

### あなたの強みとの組み合わせ

- **AWS SageMaker** + MLflow = 実験管理 + スケーラブルな訓練
- **Rekognition** + 転移学習 = カスタム画像認識
- **Lambda** + モデル API = サーバーレス推論
